回顾

上节课我们讨论了不同的深度学习框架,讨论了 PyTorch，Tensor Flow还有 Caffe2。深度学习框架的优点有：

+ 快速构建大型的运算网络，例如大规模神经网络和卷积神经网络。
+ 快速计算网络中的梯度，同时能够计算所有中间变量的权重并用来训练模型。
+ 在 GPU 上高效运行

这些框架主要是通过调制神经网络中的前向层和后向层来工作。使用时只需要定义神经网络层的顺序。就可以很快构建一个很复杂的神经网络架构。

# 介绍

会讨论一些特定类型的卷积神经网络架构，在研究和实际应用中使用得很广泛。深入探讨那些 ImageNet大赛获胜者用的最多的神经网络架构，按照时间顺序它们分别是是 AlexNet，VGGNet，GoogleNet 和 ResNet。然后简单介绍些其他的目前并不常用的架构。

# LeNet

LeNet可以看作是卷积网络的第一个实例，并且在实际应用中取得成功。

下图就是 LeNet 的结构，输入一个图片，使用步长为1大小为5x5的卷积核，接下来重复卷积和池化操作，最后有一些全连接层。LeNet在数字识别领域的应用方面取得了成功

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204221352033.png" alt="image-20220422135217947" style="zoom:67%;" />

# AlexNet

AlexNet是第一个在 ImageNet 的分类比赛中获得成功的大型卷积神经网络。AlexNet 在2012年参赛，之前的非深度学习架构相比，它大幅提高了识别准确率。从此开始了大规模对卷积神经网络的研究和应用。

下图是**AlexNet 的基础架构**：卷积层，池化层，归一化层，卷积，池化，归一化层然后是三个卷积层一个池化层，最后是三个全连接层。它看上去和 LeNet 很相似，区别在于总层数变多了，卷积层达到了五层，在最后的全连接层输出分类之前，多了两层全连接层。

![image-20220422144714052](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204221447154.png)

## 详解AlexNet 架构

### 第一层卷积

第一个卷积层有96个步长为4的大小为11×11的卷积核

输入：AIexNet 的输入也就是 ImageNet 上的数据集，227x227x3 的图像矩阵。

输出：卷积层输出的维度是 55x55x96。，卷积后的长，宽可以根据公式$(width +2 * padding - filter)/stride + 1$ 算出，在这个例子中，就是 $ (227-11)/4+1=55$。图像的长宽相等，所以卷积后的长款也是相等的，都是 55 。卷积后的深度就是卷积核的个数，即 96。

参数数目： 96\*11\*11\*3，我们有96个 11 * 11 的卷积核，每一个卷积核都会处理一个11 * 11 * 3的数据块。因为输入数据的深度是3，所以卷积核的深度是3。第一层参数总共是 96 * 11 * 11 * 3 个。

### 第二层

第二层是池化层，采用步长为2，进行池化操作。

输出维度：27 * 27 * 96，因为池化层会保留数据深度，所以我们输入的数据深度是96，那么输出的深度也是96。

参数数目：0，池化层是不需要参数的。参数是我们需要训练的权重，在池化的操作中，我们只是观察池化区域并取最大值，没有需要训练的参数。

### 全连接层

依词类推，我们得到AlexNet 架构，包括完整的输入和输出的维度。

1. [227x227x3] 输入
2. [55x55x96] 第1个卷积层: 96个11x11的卷积核，步长为4，填充为0 
3. [27x27x96] 第1个最大池化层：3x3 卷积核，步长为 2
4. [27x27x96] 第1个归一化层: 归一化层
5. [27x27x256]  第2个卷积层: 256个5x5 卷积核，步长为1，填充为2
6. [13x13x256] 第2个最大池化层：3x3 卷积核，步长为 2
7. [13x13x256] 第2个归一化层: 归一化层
8. [13x13x384] 第3个卷积层: 384 个3x3 卷积核，步长为1，填充为1
9. [13x13x384] 第4个卷积层: 384 个3x3 卷积核，步长为1，填充为1 
10. [13x13x256]  第5个卷积层: 256个3x3 卷积核，步长为1，填充为1 
11. [6x6x256] 第3个最大池化层：3x3 卷积核，步长为 2
12. [4096] FC6: 4096 个神经元
13. [4096] FC7: 4096 个神经元
14. [1000] FC8: 1000 个神经元 (class scores)

最后的层是 FC8，它连接一个soft max 函数，进行1000 个类别的 Image Net 图像分类。

### 一些训练细节

1. 这是**第一次使用 ReLu 非线性函数**
2. 使用了本地归一化，通过相邻通道来归一化响应。现在已经被摒弃了，有研究表明它不太有效果。
3. 在提出AlexNet 中的论文里，**有大量的数据增强操作**，如翻转、晃动、裁剪、颜色归一化等。当并展类似例子中的工程时，这些方法非常有用。
4. 使用了Dropout 
5. batch size 设置为128
6. 使用了带有动量的SGD，系数为0.9
7. 一般由不大的学习率，从$10^{-2}$开始学习，每到鞍点时，学习率除以10，直到网络收敛，训练结束。
8. 使用了权重衰减
9. 集成训练多个模型，然后取平均来提高性能（错误率从18.2% 降到了15.4%）
10. **将网络拆成两部分，在两个GPU里运行**。（对应架构图中第一个卷积层开始分为了两部分）这主要是因为历史原因，Alexnet曾经的训练平台是 GTX580 GPUS，这是一种老的GPU，只有3G的内存。它无法容纳整个神经网络，最后的解决方案是将网络拆分成两部分，在两个GPU里运行，每个 GPU 只容纳半数的神经元。以第一个卷积层为例，这里55x55x96 的数据输出，仔细观察这个网络的图解，每个 GPU 的实际深度只有48。在 6，7，8 层，也就是 FC层中，
    GPUS 互相通信。

# 基于AlexNet 的ZFNet

AlexNet是2012年 ImageNet 分类问题的冠军，比起2011年，错误率上有很大降低。这是第一次基于 CNN 的冠军，后来，它被转换成不同的版本适用不同的任务
，应用了很长一段时期。

![image-20220423195655451](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220423195655451.png)

2013 年的 ImageNet 比赛中，优胜者是 **ZFNet**，它与用于与AlexNet 相同的层数，相同的基本结构，只是基于AlexNet 上进行了改动。

下面是ZFNet 的结构图，它改动的地方在于

1. 改变了第一个卷积层卷积核的大小及步长，AlexNet 使用 11\*11，步长为4的卷积核，ZFNet 使用 7\*7,步长为2的卷积核。
2. 改变第3,4,5个卷积层的卷积核数目，分别使用 512,1024,512 代替原本AlextNet 的384,384,256 。

![image-20220423200140078](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220423200140078.png)

## 

# VGGNet

2014年比赛出现了一些改进的架构，它们和之前网络**最大的不同是拥有了更深层的网络**。从2012年2013年的8层网络，到2014 年，两个非常接近的获胜者别是19层，22层。分别是 来自 Google 的优胜者 GoogleNet和来自 Oxford 的 VGGNet。这些都是非常鲁棒的网络。

**VGG 的思想是一个包含小卷积核的非常深的网络。**从 AlexNet的8层扩展到到VGGNet 的16-19层。关键点是他们保持小的卷积核，只用3*3的卷积（基本上是最小的卷积大小，只关注相邻的像素）定期下采样，这种思想贯穿整个网络，它是非常简炼优雅的网络，获得了ImageNet最高的7.3的错误率。

## VGG网络架构

仔细比较一下VGG与AlexNet 网络的结果会发现，**二者使用同样的方式来组织架构的，不同的是VGG 有用更多的卷积层。**对 VGG16 而言就有16层，VGG19 也是非常相似的架构，只是有更多的卷积层。

![image-20220423203103043](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220423203103043.png)

**<u>Q：为什么使用最小的卷积核？</u>**

A：当使用小的卷积核，参数量比较小。使用小的卷积核让我们可以尝试更深层的网络和更多的卷积核。使用多层小的卷积核，比起使用大的卷积核，感受野范围更大。

## 感受野

> 在卷积神经网络中，感受野的定义是 卷积神经网络每一层输出的特征图（feature map）上的像素点在**原始图像**上映射的区域大小。 ——博客园

关于感受野的详细内容，可以[点击这里](https://zhuanlan.zhihu.com/p/31004121)

## VGG 内存使用

网络内存的使用是**一次前向传播计算所占的内存量**。下图是一次输入在VGG网络中所使用的内存情况和参数数量，一个图片需要占用大约96M的内存，网络参数达到了138M。 经过观察，可以发现**大多数内存使用在前面的卷积层，大量的参数在后面的全连接层里**。

![image-20220424181305118](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204241813815.png)

## 关于VGG的其他内容

+ VGGNet在2014年的 ImageNet 图像识别赛中获得了分类项自的第二名，定位项目的第一名
+ 它和AlexNet 的训练也十分相似。
+ 不需要局部响应归一化，前面已经提过，局部响应归一化在这里没什么用。
+ 在具体时间中，可以选用VGG19或VGG16。VGG19只是稍微比 VGG16深一点，它的效果更好，但是使用了更多的内存。
+ 为了更好的效果，使用集成学习。
+ VGGNet 的最后一个全连接层 F7 能够很好地进行特征表达，在其他任务也有很好的返回能力。

# GoogleNet

GoogleNet 是图像识别大赛中的另外一个优胜者，它是**一个进行高效计算的更深的网络结构**。它
尝试着设计一个可以进行高效计算的网络架构。采用了**inception 模块**，然后在每一层顶部叠加inception模块。

这是一些关于GoogleNet 的大概内容。

- 共22层。
- 采用高效的 Inception 模块
- 没有全连接层，这样可以节省大量参数。GoogleNet只有500 万个参数，AlexNet中有6000万个参数。虽然 Google Net 更深，参数个数是AlexNet的1/12。
- top 5错误率达到6.7%

## Inception 模块

**Inception 模块的思想就是设计一个好的局部网络拓扑。**然后把拓扑结构视为一个网络，一个接一个叠放。

### 原始 inception 模块

下图是一个原始的 inception 模块图。在这个局部网络中，**inception 模块要做的就是对输入应用了不同的卷积操作。**

面对来自前一层的输入，进行不同的卷积。图中有1×1卷积，3×3卷积，5 X5 卷积，然后也有池化操作，用一个3x3 的池化。然后就**在不同的层里得到不同的输出，之后将所有卷积的输出在深度层面上串联在一起得到一个张量输出**，这个张量会进入下一层。

![image-20220424185236513](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204241852629.png)

在一个实际的例子中来看看。比如用128个1×1的卷积核，192个3×3卷积核卷积，96个5x5卷积核卷积，假设所有的步长保持一致，然后输入进来之后，会得到的输出是下图这样（黑色字代表操作的规模，框外的蓝色字体代表输出的规模）。

![image-20220424190524614](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204241905747.png)

从深度层面上叠加，最终的规模是 28x28x672。其中 672 是 128+192+96+256 的结果。综上，我们inception 模块的输入是28×28×256，经过不同的卷积核处理后输出是28x28x672。
在原始的inception模块，我们保留了相同的尺寸然后扩充了深度。

在这个过程里总共做了多少次运算呢？

对于第一个卷积核，也就是1x1 的卷积核，每一个位置上我们会做 1x1x256 的点积运算。
每一个特征图都有空间位置，每一个空间位置做一次256的相乘，我们在这一层总共有128 个卷积核
也就是说我们会生成128 个特征图，所以总共需要的运算次数是28x28x128x256。以此类推，可以得出对于 3x3 的卷积核，运算次数是 28x28x192x3x3x256，对于5x5的卷积核，运算次数为 28x28x96x5x5x256。总共的运算次数是 8.54 亿次。这对计算力消耗庞大。

另外一方面，池化层也需要进行运算。而且池化层是保留了整个特征图的深度，所以在每一层深度只能增加。并且随着继续执行，深度越来越大。

**<u>Q：为什么输入了输入和输出都是 28* 28?</u>**
A：我们采用了零填充的方法来让输入和输出保持一致，通过卷积核操作 来增加深度。

**<u>Q：输入的深度是256代表什么？</u>**
A：这个256 并不是神经网络的输入，只是针对当前的模块而言的。是前一个模块的输出规模深度
为256。这个模块的尺寸大小是28x28x672，将会作为下一个模块的初始输入。

### 降维的 inception 模块

我们该如何处理深度逐渐增加的问题呢？一个很好的方法是 **增加一层瓶颈层，尝试在卷积运算之前降低特征图的维度。**

先解释下**瓶颈层**，为了减轻昂贵的计算，**在3x3和5x5卷积层之前，和池化层之后，加入一个1x1 的卷积层**，这个多出来的 1x1 的卷积层就是添加进来的瓶颈层。

![image-20220424192653841](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204241926984.png)

那具体是如何降维的？加入了64个 1x1 的卷积核 来减少深度，此时输出是28x28x64。所以现在进入3x3 卷积层和5x5 的卷积层的输入都是28x28x64。在池化层，是先进行池化，结束以后减小输出的深度。

此时，卷积操作的运算次数是

- [1x1 conv, 64]  28x28x64x1x1x256
- [1x1 conv, 64]  28x28x64x1x1x256
- [1x1 conv, 128]  28x28x128x1x1x256
- [3x3 conv, 192]  28x28x192x3x3x64
- [5x5 conv, 96]  28x28x96x5x5x64
- [1x1 conv, 64]  28x28x64x1x1x256

总的运算量大概是3.58亿次 ，相比8.4亿次，已经大幅度减少了。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204241937656.png" alt="image-20220424193722542" style="zoom:50%;" />

**<u>Q：一开始用1*1卷积去计算会丢失什么信息？</u>**
A：结果可能会有一些信息丢失，但与此同时，使用具有冗余的输入特征映射的线性组合把它们组合在一起。也可以在1*1卷积之后，引入一个额外的非线性组合，这也有助于增加一点点深度。总的来说这个效果更好

## GoogleNet 结构

下图是完整的GoogleNet 结构图

蓝色框部分：一个 stem network，跟原始的卷积网络没什么区别

红色框部分：将inception模块一层层叠加

黄色框部分：网络的结尾部分，这里使用softmax 进行分类输出，移除全连接网络

绿色框部分：两个额外的分支，它们是辅助分类输出。在训练时，为了避免梯度消失而加上的，模型训练好后就拿掉。

这就是完整的架构，有22个有权重的层，在每个inception模型中，1\*1，3\*3，5\*5的卷积核组成一个权重层。这是个相对比较精心设计的架构，部分设计来源于inception，部分设计是来自谷歌的开发者，他们有巨大的集群可以交叉验证各种设计，使得最终运作良好。

![image-20220425104543387](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251045633.png)

**<u>Q：瓶颈层(bottleneck 层)能不能使用其他的降维？</u>**
A：可以，使用1\*1的卷积核的好处是：它是和其他层一样的卷积层，训练这些核心网络，就可以达到效果。

**<u>Q：每个权重是共享的还是独立的？</u>**
A：每层的权重都是独立的。

**<u>Q：为什么要在前面的层中注入梯度？</u>**
A：分类输出在最后，通过了整个链得到一个梯度。但当网络深度很深时，一些梯度信号会变得越来越小，甚至丢失开始的那些梯度信号。为了提供一些额外的信号，在前面部分添加额外的梯度。

# ResNet

接下来看2015 年的获胜者ResNet——残差网络，这个想法是深度网络的一次革命。关于残差网络

- 使用残差连接的非常深的网络
- 在 Image Net上有152层的模型
- ILSVRC’15  分类的获胜者， top 5 的错误率达到了3.57%
- 横扫了ILSVRC’15 和 COCO'15 所有分类和检测竞赛的奖项

## 网络变深能够取得更好的效果？

以VGG或者其它正常的网络为例，它们只在开始使用了卷积和池化的层。那么自然而然，我们会思考这样一个问题，仅仅只持续扩展层数取得更好的效果吗？

答案是不能。这里只用普通网络，比较一个20层和56层的网络。可以看出在右边的测试误差图中，
56层的网络表现不如20层的网络。

这样的结果是不是因为过拟合造成的？并不是，过拟合是很低的训练误差和很高的测试误差，但实际观察左图可以发现，在训练误差中56 层的网络的表现也不如 20 层的网络。所以**更深的网络不能表现得更好。**

ResNet 的创造者假设，这实际上是一个优化问题，**相比于浅的网络更深的模型更难优化**。理由是，**从较浅的模型中找到那些学习的层，通过恒等映射，把这些拷贝到深的模型中，深的模型能够和一个浅的模型表现得一样好。**

![image-20220425112510371](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251125428.png)

在这个解决方法的驱动下，思考如何使模型更高效地学习？ 
**尝试并拟合残差映射代替拟合直接映射**
下图右边就是它的原理，残差块的输入是原始传输进来的输入，我们使用层去拟合残差 H(X)-X 代替 H(x)。在这个块的最后，我们连接输入和最后的输出。将输入并作为一个不变的量传递，如果中间没有权重层，这个值它将是一直不变的。我们现在使用额外的权重层去学习 x 的残差，输出就变成原始的 x 加上残差。

![image-20220425114000245](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251140300.png)

## ResNet 结构

这是一个完整的ResNet 结构图。

+ 在网络开始的地方，有额外的卷积层（结构图中橘黄色的层）。
+ 中间是将残差块堆叠在一起，组成一个很深的网络。

+ 每个残差块都有两个3*3的卷积层，这是一个不错的配置。
+ 有时会使用两倍数量的卷积核，用步幅为2 的卷积核进行下采样。（图中紫色层的部分）
+ 在网络层的最后，没有全连接层，只有一个全局的平均池化层。它在空间上取平均，输入到最后的1000 种分类中。

这就是完整的 ResNet 的结构，非常的简单和讲究。它只是把残差块互相堆叠，深度可以达到34，50，100层。在 Image Net比赛中尝试过152层。

![image-20220425122009189](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251220254.png)

## 提高ResNet 计算效率

对于一个非常深的网络来说，可以**使用与 GoogleNet 相似的瓶颈层来提高效率**。

比如有一个28×28×256的输入，首先用1\*1的卷积核将其深度降低，得到64×28x28的数据输出。
然后使用3\*3的卷积核操作，注意这里他们只使用一个 3\*3的卷积核，减少步数来使得它的代价更小。之后进行另一个卷积操作，使得它的深度能够恢复为原来的256 层。

![image-20220425122916403](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251229450.png)所以现在在每一个块上你要做的是

## 一些训练细节

+ 在每个卷积层之后使用批量正则化
+ 使用Xavier 初始化权重
+ 使用带有动量的SGD，动量系数为0.9
+ 初始学习率为0.1，当验证错误率停滞将学习率除以10
+ batch size 设置为256
+ 权值衰减
+ 没有使用dropout

## 实验结果

通过ResNet的实验结果可以知道：

+ 在没有退化的情况下，可以训练非常深的网络。ResNet 在ImageNet 上达到了152层，Cifar 上达到了1202层。
+ 深度网络可以像期望的那样，训练错误率很低。
+ ResNet 在2015年ILSVRC和 Coco比赛中以压倒性的优拿到第一名，在分类挑战中top 5 错误率达到3.6%，已经优于人类在ImageNet 中所记录的表现了。

# 各种模型的比较

性能比较的图来自于论文： An Analysis of Deep Neural Network Models for Practical Applications, 2017

## 复杂性比较

以上就是我们最近使用的主要神经网络模型，最开始使用了 AlexNet 算法，VGG和 Gooqle Net也都很流行。ResNet 是最近一段时间来表现最好的模型，如果你想寻找某种算法训练一个新的神经网络模型，应该用 ResNet。

左图是按照算法性能排序的图，Y轴是精度，X轴是各种不同的模型。其中Inception v4是效果最好额，它是ResNet 和 Incepetion 的一个结合。

右图是计算复杂度的分类情况，Y轴表示精度，X轴是操作次数。圆形的半径表示内存的占用。可以看到，这些绿色的 VGG 算法是效率最低的，它们使用了最大的存储空间，最多的操作次数，但是效果确实很好。GoogleNet 在这里是最有效的，它的空间用量在算法训练的过程中一路下降，最终只使用了很小的内存空间，相对比较小规模的运算，特别高效。AlexNet 是早期模型，准确率是最低的，它是一个小的神经网络，内存占用比较大。ResNet 拥有中等效率，它在内存使用和操作复杂度之间实现了一种平衡，有着最高的准确率。

![image-20220425133107365](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251331630.png)

## 前向传播时间和耗电量比较

左图表展示了以毫秒为单位的前向传播的时间。VGG算法进行200毫秒的前向传播。

右图展示了不同算法的耗电量。

![image-20220425141216338](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251412125.png)

# 其他的CNN架构

## Network in Network (NiN)

NiN 提出了一个 MIP 卷积层。

+ MLP卷积层可以看成是在传统CNN卷积层中包含一个微型的多层网络，它能够局部图像块计算更多的抽象特征。
+ MLP 使用了多层感知机。
+ 它是GoogleNet 和 ResNet 中瓶颈层的前身

![image-20220425142936356](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251429497.png)

NiN 的结构中将多个MIP层堆叠起来。

![image-20220425143416555](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204251434691.png)
