# 15 训练神经网络(下)

# 回顾

快速回顾下我们上节课的内容。

## 激活函数

我们讨论了各种各样的激活函数。我们看到，大概在10年前，sigmoid 激活函数曾经在训练神经网络方面十分流行，但是存在梯度消失的问题。tanh 函数也存在类似的问题。对于这样的问题一般的建议是你可能想要在大多数情况下，把Relu 函数作为默认的激活函数。因为它在不同的框架下都能够运行的很好。

![image-20220412184855745](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121848814.png)

## 权重初始化

我们也讨论了权重初始化，首先要记住的是，当你们在开始训练的时候，初始化你们的权重值（即参数w）,如果那些权重的初始值太小，你就会发现激活值消失。因为你不断乘以这些很小的数，那么最终他们就会衰减为0，学习也就无从谈起。

从另一个角度来说 ，如果你的权重初始值太大，那么这些初始值不断地乘以你的权值矩阵，最终会产生梯度爆炸，无法学习。

但是如果你正确地初始化参数，举个例子，使用Xavier 初始化法 或者MSRack初始化法，那么在你学习神经网络的每一层，激活值都有很好的分布。记住在深度网络越来越深的情况下，权重初始化会变得至关重要。因为随着网路的变深，将不断地乘以那些权值矩阵。

## 数据预处理

我们讲过，在卷积神经网络中，中心化和归一化是非常常用的手段。它会使数据分布均值为1，方差为0。

![image-20220412184933962](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121849059.png)

我想在直观的讲一下这样做的原因：举一个简单的例子，我们要通过二元分类的方法分离这些红色和蓝色的点，从左边的图来看，如果数据点没有被归一化和中心化，而且距离坐标原点很远，虽然我们仍然可以用一条直线分离它们，但是如果这条直线稍微转动一下，那么我们的分类器将被完全的破坏。这意味着，在左边的例子中，loss 对我们的权重矩阵中的线性分类器的小波动非常敏感。我们仍然可以表示相同的函数，但是这会让深度学习异常艰难。因为它们的损失对我们的参数向量非常敏感。

而在右边的情况下，如果你使用数据集的时候，将数据点移动到原点附近，并且缩小它们的单位方差，我们仍然可以很好地对这些数据进行分类。但当我们稍微转动直线时，损失函数对参数值中的小波动就不那么敏感了。这可能使得优化变得更容易一些的同时，能够看到一些进步。而且，这种情况不仅仅在线性分类中遇到。记住，在神经网络中我们需要交叉地使用这些线性矩阵相乘或者卷积，还有非线性激活函数。如果神经网络中某一层的输入均值不为0或者方差不为1，该层网络权值矩阵的小波动就会造成输出的巨大波动，从而造成学习困难。所以，这就直观的解释了为什么要归一化。

![image-20220412184948257](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121849323.png)

还要记住，因为我们了解归一化的重要性，所以引入了Batch normalization 的概念。即在神经网络中加入额外一层，以使得中间的激活值均值为0，方差为1。在这里，我通过更直观的形式总结了Batch Normalization 的方程。在batch normalization 中，正向传播的过程，我们使用小批量数据计算平均值和标准差，并使用这个估计值来对数据进行归一化。之后我们还介绍了缩放参数和平移参数增加层的可表达性。

![image-20220412185009320](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121850405.png)

## 跟踪学习过程

上次我们还介绍一部分跟踪学习过程，比如在训练过程中，如何观察损失曲线。以下是一些神经网络的例子，这是我在周末实际训练过过程中发现的。这通常是我在研究问题中的一些例行公事。

![image-20220412185054027](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121850126.png)

左侧是随时间变化的损失函数曲线，你可以看到曲线多多少少是下降的。说明神经网络的损失在下降，这是一个好的信号。右侧曲线，x轴同样是训练时间或者迭代次数，y轴表示模型在测试集和验证集上的效果。你会发现，随着时间增加，训练集上的效果随着损失的下降到某一点之后不再上升。这说明模型进入了过拟合状态，这时候就需要加入其他的正则化手段。

## 超参数搜索

所有这些神经网络都涉及到大量的超参数，找到正确的参数十分重要。我们讲到了**网格搜索**，以及**随机搜索在理论上的优越性**在哪里。因为当你的模型性能对一个参数比对其他超参数更敏感时，随机搜索可以对超参数空间覆盖地更好。我们还介绍了==**粗细粒度交叉搜索==**，当你做超参数优化时，一开始可以会处理很大的搜索范围，几次迭代之后，就可以缩小范围，圈定合适的超参数范围。然后再对这个小范围，重复上述步骤，以获得超参数正确的区域。另外很重要的一点是，一开始你要确定超参数粗略的范围，这个范围要非常宽，覆盖你所有的超参数。理想情况下，范围应该足够宽到你的网络不会超过范围的任意一边。这样你就知道自己的范围足够大。

![image-20220412185104054](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121851181.png)

Q：通常一次搜索几个超参数

A：例子中给的是2个，通常会超过2个，这主要取决于你的模型和架构。由于超参数可能性的数量是以指数增长的，所以其实一次性没办法处理太多的超参数。这还取决于有多少设备能为你所用，所以这是因人而异，因实验而异的。通常我每次不会处理超过2个，3个甚至4个超参数。因为这会让指数搜索失控。通常  **学习速率**  是最重要的，首先确定它，其他的诸如正则化，学习速率衰减稀疏，模型大小等参数不那么敏感，跟学习速率相比。所以一般需要反复迭代，找到最佳学习速率然后返回，去寻找不同的模型大小。这能帮你减少实验搜索的时间。这个问题通常取决于以 什么样的顺序搜索数据。

Q：当你改变一个超参数时，其他超参数的最佳值有多大可能性会改变？

A：这有时确实会发生，虽然对于learning rate来说这方面一般不是问题。对于learning rate来说，你需要找到一个好的范围，然后设定得比最佳值稍微小一点，让他运行很长时间。采取这种方法，再加上优化策略——我们今天要学的，你会发现很多学习模型在你找到好的范围之后对learning rate 就不那么敏感了。

Q：降低learning rate，增加时间点的数量有什么问题吗？

A：你可能就就会花费更多的时间 😄。 确实，直观上看，如果你把learning rate 设的很低，让他持续很长时间，这在理论上是行的。但实际上，参数是10还是100对实验室很重要的。如果采用何时的learning rate ，可能几个小时或者一天完成训练。如果你只是为了保险，把10换成了100，那么1天的训练可能就变成了100天的训练。这就像是你去上计算机课，通常会忽略常量，但是在实验中，常量就非常重要了。

Q：对于learning rate 会不会出现卡在局部最小值的情况？

A：直觉上是可能的，但实际上并不是。我们今天会讨论这个问题。

今天我要说的是其他几个有趣又重要的话题，它们都跟神经网络训练有关。特别要说的是，我们提过更有效的优化方法。今天我想花点时间深入介绍。以及近年来人们用的最多的优化算法。我们也会涉及之前提到的正则化 ，这可以减少训练和测试误差之间的鸿沟。 

谈到神经网络，我更多想讲的是人们实际使用的正则化策略。最后我想讲一下**迁移学习。**当你拥有的数据比想象的时候少时，你可以通过它将一个问题转换为另一个问题。

# 引入优化策略

## 回顾SGD

回想一下之前的课程，训练神经网络的核心策略是一个优化问题。我们写下损失函数，定义网络权重的每一个值，损失函数告诉我们这些权重值在解决我们的问题时表现是好是坏。我们设想在当前权重下，损失函数给了我们漂亮的等高线图。这是一个二维问题，X 和Y轴表示两个权重值，图上的颜色表示损失值。在这个二维问题的卡通图中，我们只优化两个值 $w_1$ 和$w_2$，目标是找到红色最深的区域。在这种情况下，对应了损失最小的权重值。

记住我们已经使用过最简单的优化算法-SGD，它非常简单，只有三行代码。我们首先评估一下小批量数据中损失的梯度，然后向梯度的负方向更新参数向量。因为它给出了损失函数下降最快的方向，然后重复这个过程。幸运的化，它在红色区域收敛，我们如愿得到很小的误差值。遗憾的是，这个相对简单的优化算法在实际使用中会产生很多的问题。

![image-20220412185115633](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121851753.png)

## SGD存在的问题

SGD 的问题之一 ：想象一下我们的目标函数发生了什么，就像这样，我们画两个值，W_1 和W_2 ，当我们在水平方向上改变值，损失函数变化非常慢、当我们在等高线上下方向运动时 ，损失值则对垂直方向的变化非常敏感。对于损失值来说，在这一点上是很坏的情况。在这一点，它是海森矩阵中最大奇异值与最小奇异值之比。但是直观来看，损失值等高线图就像是一个玉米卷饼，它在一个方向上非常敏感，而在其他方向上不敏感。问题是对于一个像这样的函数，SGD会做什么？如果你在这类函数行运行SGD，就会的得到下图这样的之字图形。这是因为这类目标函数梯度的方向并不是与最小值成一条线，当你计算梯度并沿着前进时，你可能一遍遍跨过等高线，之字形地前进或后退，所以你在水平方向上前进速度非常慢，在这个方向上敏感度较低。但是在非常敏感的垂直维度上， 对水平方向梯度不敏感，这并不是我们所希望的，而且，事实上，这个问题在高维空间变得更加普遍。在这里，我们只展示了两维优化等高线图，在神经网络中，可能存在上百万甚至上亿个参数。它会沿着上亿个方向进行移动，在不同的运动方向上，介于最大值和最小值的方向上的比例很高，SGD的表现并不好。你可以想象一下，我们有上亿个参数，在它们两者之间的最大比例可能很大，因此，我认为在多维问题中，这是一个大问题。

![image-20220412185125097](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121851197.png)

SGD的另一个问题是局部最小值或鞍点。这里我把图形做小小改动，X轴显示参数的值，Y轴显示损失值。在上面的例子中，我们有这类函数的目标函数，在曲线中间有一段凹陷。这种情况下，SGD会卡在中间。因为那里是局部最小值，梯度为0，因为那一段是平的。还记得SGD计算梯度，向着梯度相反的方向前进，在目前的点上，相反的梯度值为0，我们会被卡在这个为止。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121851945.png" alt="image-20220412185140914" style="zoom: 33%;" />

关于鞍点，还有另一个问题，相比于局部最小值，你可以设想在一点上，往一个方向是是向上，另一个方向是向下，在这种情况下，损失函数会被卡在鞍点。因为在这里梯度为0。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121851752.png" alt="image-20220412185157721" style="zoom: 33%;" />

我希望指出一点，在一维问题上，局部极小值看起来是个大问题，鞍点看起来并不需要担心。但是事实上，一旦涉及到高维问题恰好相反。想象一下一亿参数的空间，鞍点意味着在当前点上，某些方向的损失会增大，某些方向的损失会减小。如果维度是一亿，它会发生的更加频繁，几乎任何点上都会发生。然而在局部极小值点上，在一亿个方向上，任何一个方向前进损失都会变大，事实上，当你考虑这种很高维问题时，这种情况很稀少。这个问题时最近这几年在训练非常大的神经网路时才显示出来。问题更多的出现在鞍点上，局部最小值问题少一点。不过，有时问题并非恰好在鞍点上，也可能在鞍点附近。如果你看看鞍点附近，就可以看见鞍点附近梯度并不是0，但是斜率非常小。这意味着如果我们向梯度方向前进，而梯度非常小，任何时候当当前参数值在目标等高线图上 接近鞍点时，进展会非常缓慢。

SGD的另一个问题是随机性。SGD是随机梯度下降，回忆一下，损失函数是通过多次重复计算不同实例的损失来定一个的。在这个例子中，如果N是这个训练集的长度，可能有100万个，每次计算损失都会耗费很大的计算量。事实上，我们通常通过小批量的实例来对损失和梯度进行估计。这意味着并不会每一步都去计算真实的梯度，而是在当前位置对梯度进行噪声估计。

下图是我对图做了一点修改，我只是在每一点的梯度上加入了随机均匀噪声，搞乱梯度，再这样的噪声条件下运行SGD，这可能并不完全是SGD发生的事情，但是这仍然能给你一种感觉，如果在你的梯度估计中存在噪声，那么常规的SGD这种周围曲折的空间可能实际上需要花费很长时间，才能得到极小值。

加入均匀噪声后，训练轨迹如下：

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121852815.png" alt="image-20220412185208720" style="zoom: 33%;" />

Q：如果我们使用正常的梯度下降，这些问题都会消失吗？

A：如果在全量梯度下降中加入噪声，噪声，像我们看到的一样，我们有时可能会在网络中引入额外的噪声，不仅仅是因为小批量采样，还因为网络中具有明确的随机性。这仍然会是一个问题。鞍点，对于全量梯度下降仍然是一个问题。因为在目标函数的全等高轮廓线中也会存在鞍点。

# 优化策略（一）

## SGD+ Momentum

为了解决上述的问题，我们在SGD中加入一个动量项。 下图左侧是经典的SGD，只在梯度方向上前进。但在右侧，有一个非常小的方差，称之为带动量的SGD。思想是，保持一个不随时间变化的速度，并且把梯度估计加到这个速度上。然后再速度的方向上前进，而不是在梯度的方向上前进。这里出现了一个代表摩擦系数的超参数 $\rho$ 。之后的每一步，我们采用当前的速度，然后用摩擦系数$\rho$  来对其进行衰减，再加到梯度上。($\rho$经常取值较大，通常选择0.9）这个简单的策略可以解决上述所说的局部最小值和鞍点问题。

![image-20220412194739582](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121947645.png)

那么在局部最小值点或者鞍点发生了什么，可以想象这个系统中的速度就像是一个球滚下山，他会在下降时加上速度。一旦加上速度，在通过局部最小点时虽然没有梯度，仍然还有速度，就能越过当前局部最小点。在鞍点处也是如此，虽然鞍点附近的梯度非常小，但我们还有下山时就建立起来的速度向量。这能够帮助球通过鞍点，并且继续滚动下去。

让我们思考一下，如果在曲折的梯度附近会发生什么? 一旦使用动量，这些之字形的曲折就会互相抵消，这能够有效减少我们朝敏感方向前进步数的数量。而在水平方向上，速度会不端增加，在其他不敏感的维度上，速度会加速下降。因此添加动量，实际上能够帮助处理高条件数的问题。下图中，下图重现了带有噪声的梯度下降过程，黑色的曲线代表常规的SGD，蓝色的曲线代表带有动量的SGD。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121940880.png" alt="image-20220412194030784" style="zoom:33%;" />

Q： SGD动量如何处理条件很差的坐标

A：回顾下速度估计和速度计算，就会发现我们在每一步都增加了梯度。这在一定程度上取决于你的摩擦系数$\rho$的设置。如果梯度较小，并且这种情况下 $ρ$ 表现地很好，我们的速度可以单调递增到一个速度比实际梯度更大的点，然后我们可能会更快地处理条件差的维度。

当我们在使用带有动量的SGD时，可以这样想象，红色的点是我们的当前为止，红色的向量表示梯度的方向，绿色向量是速度向量的方向，当我们做动量更新时，实际上我们是根据两者的平均权重进行步行。这有助于克服梯度估计中的一些噪声。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204121951864.png" alt="image-20220412195158832" style="zoom: 50%;" />

## Nesterov 动量

 当看到一个梯度的微量变化时，叫做 ==**Nesterov 加速梯度**==，也可以称为为 Nesterov 动量。他把这个顺序改变了一下，在普通的SGD动量中，我们估计梯度，然后取速度和梯度的混合。但是在 Nesterov 动量梯度中，你从红色的点开始，然后再取得的速度方向上进行步进，之后评估这个位置的梯度，随后回到初始位置，将这两者混合起来。

<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20220413131827691.png" alt="image-20220413131827691" style="zoom:50%;" />

如果速度的方向实际上有一点错误，那它可以让你在目标函数的等高轮廓图更大一点的部分中加入梯度信息，在凸优化问题上有一些很好的理论性质。但一旦涉及到诸如神经网络的非凸优化问题就
会有一些问题了。

Nesterove 动量等式如下图。更新速度的步骤如下：我们根据之前的速度来前进一步，然后计算此处的梯度，当我们前进下一步时，实际上是在速度的方向上步进。这就是从多个点合井信息。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131345844.png" alt="image-20220413134525811" style="zoom:50%;" />

Q：一个速度应该怎么初始化才算好？

A：基本上都是初始化到0，它甚至不是超参数。（也就是说不需要训练得出）。直觉上，速度是你所看到的梯度的一个加权和。随着最近的梯度权重越来越大，在每一步我们都采用旧的速度通过摩擦系数衰减然后再加上当前的梯度，你可以把它看作是一个**最近梯度平均的平滑移动**，并且在梯度上有一个能够及时回来的指数衰减权重。 

## 改进 Nesterov 公式

Nesterove 公式有一点不方便，因为当你在使用 SGD 法优化神经网络时你通常会希望能同时计算损失函数和梯度，而 Nesterov 的动量优化形式会对此造成破坏，从而造成应用上的麻烦。
使用换元法可以改进 Nesterov 公式。

一旦做了这样的换元，第一步的式子，看起来和常规 SGD 动量优化法中更新速度向量是一样的。
我们计算当前点的速度和梯度，并且将两者用相减的方式混合。
在第二步中我们实际上在更新我们的参数向量，看第二个等式，我们用当前点参数向量加上当前速度再加上一个权重化的这一次的速度和上一次速度的差。这里我们可以说 Nesterov 动量包含了当前速度向量和先前速度向量的误差修正。

![image-20220413134444077](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131344132.png)

## SGD，SGD+动量 和 Nesterov 效果

在这个简单的例子中进行比较，可以看到，代表 SGD 的黑线在训练中会逐渐被困在局部极小点。
而代表动量优化法和 Nesterov 动量法的蓝线和绿线会借着他们构建的速度从而越过局部极小点。
因此这两种方法能自我修正，从而到送真正的极小值点。二者的一处不同就是，由于 Nesterov 有校正因子的存在，与带动量的SGD相比它不会那么剧烈的越过局部极小值点。（在图中的表现是绿色的线在越过局部极小值时曲线更加平滑）

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131354561.png" alt="image-20220413135430455" style="zoom:50%;" />

Q： 这个图看起来很不错，但是如果实际情况是如果你的局部极小点在一个非常窄的盆地里呢，上面两种优化方法带来的速度能否让你越过这个局部极小点？

A：事实上这些非常极端的局部极值是所谓的坏点。我们的算法甚至不会经过这些点。因为实如果你遇到了一个非常极端的极值点，那么你的训练很有可能已经过拟合了。如果能够扩大训练数据集到两倍，那么整个优化函数的形状都会改变，以至于这个非常极端的极值点会消失。前提是我们
能够收集更多的训练数据。我们可以得到的一个直觉判断就是我们愿意去靠近一个相对平缓的极值点，因为这样的平缓极值点往往针对测试数据有更好的泛化能力。某种意义上来说跳过这些非常尖锐的极值点是带动量的 SGD 的一个特性。

# 优化策略（二）

## AdaGrad

 AdaGrad  是斯坦福教授 John Duchi 教授在他攻读博士期间提出的。**AdaGrad 的核心思想**是在优化的过程中，需要记录一个在训练过程中的每一步的梯度的平方和。与速度项不同的是，现在多了一个梯度平方和，在训练时 我们会一直累加当前的梯度平方到这个梯度平方项。当更新参数向量时，我们会除以这个梯度平方项。

![image-20220413141428944](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131414994.png)

<u>**对于矩阵中条件数很大的情形，AdaGrad有什么改进呢?**</u>
如果我们有两个坐标轴,沿其中一个轴我们有很高的梯度,而另一个轴方向却有很小的梯度。随着我们累加小梯度，从而加速了在小梯度维度上的学习速度。在另一个维度方向上，由于梯度变得特别大，
我们会除以一个非常大的数从而降低这个维度方向上的训练进度。

![image-20220413143122576](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131431660.png)

**<u>当t (时间)越来越大的时候，在训练的过程中使用 Ada Grad会发生什么?</u>**

**使用了 Ada Grad，步长会变得越来越小**。因为我们一直在随时间更新梯度平方的值，而这个估计值
在训练过程中一直随时间单调递增。这会导致我们的步长随着时间越来越小。

## RMSProp

有理论证明，在学习目标是一个凸函数的情况下AdaGrad 效果很好。因为当你接近极值点时 你会逐渐的慢下来最后到达收敛。这点是( Ada Grad ) 在凸函数情况下的一个很好的特性。但是在非凸函数的情况下事情会变得复杂，因为当你到达一个局部的极值点时，使用AdaGrad会让你在这里被困住，
从而使得训练过程无法再进行下去。因此 Ada Grad 有一个变体叫做 RMSProp。

在 RMS Prop 中仍然计算梯度的平方，但是并不是仅仅简单的累加梯度平方。
而是我们会让平方梯度按照一定比率下降，它看起来就和动量优化法很像，不过我们是给梯度的平
加上动量而不是给梯度本身。

在RMSProp中，计算完梯度之后，取出当前的梯度平方将其乘以一个衰减率，通常是0.9或者是0.99
然后用1减去衰减率乘以当前梯度的平方和，再加上之前的结果。
随着训练的进行可以知道，步长和 Ada Grad 一样会有一个良好的性质。在一个维度上(梯度下降很慢的)训练会加快，而在另一个维度方向上训练减慢。

![image-20220413144144663](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131441739.png)

由于梯度平方估计被衰减了，这有可能会造成训练总是一直在变慢。这可能不是我们想要的。
在下图中可以看到 RMS Prop和带动量的 SGD效果都比单纯的 SGD 要好。但是它们在轨迹上有一点不同，带动量的 SGD 会先绕过最小值然后又拐回来，但是使用RMSProp 的话，它就一直在调整
自己的路线，在每个维度上做出了大致相同的优化。
这个图也展现了使用相同的学习率下的AdaGrad 算法（绿线），但是它走着走着就因为不断
减小的学习率就卡住了。在实际应用中- Ada Grad 可能不太会出现这种问题。这个比较对 AdaGrad
不太公平。也许你需要在使用 Ada Grad -时提升学习率，然后它就可以表现得像 RMS Prop 那样好。但是通常来说在做神经网络训练时，我们倾向于不使用 Ada Grad。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131451111.png" alt="image-20220413145146002" style="zoom:50%;" />

## Adam 

在动量中，我们有关于速度的概念。我们通过梯度的叠加得到速度，然后顺着速度的方向走。在 AdaGrad 和 RMS Prop 中我们有另一套方法，先求梯度平方的估计值然后除以梯度平方的累加值。
这两种方法单独来看都不错，那么我们为什么不把它们结合到一起呢？也许那样效果会更好。这就引入了Adam 算法，或者说接近 Adam 的算法。

![image-20220413150719964](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131507021.png)

使用 Adam 我们更新第一动量和第二动量的估计值，在红框里我们让第一动量的估计值等于我们梯度的加权和。第二动量的估计值等于梯度平方和的动态近似值，就像是AdaGrad 和 RMSProp中一样。接着来更新参数，使用第一动量（有点类似于速度）除以第二动量的平方根。
**Adam 的思想看起来像动量加上第二个梯度平方**，合并了两者各自好的性质。

### Adam 的问题

Adam 可能存在一些问题，这个问题就是在最初的初始化部分。我们已经将第二动量初始化为0。通常 $β_2$ 也就是第二动量的衰减率大概是0.9或0.99，非常接近于1的一个数。经过一次更新后，第二动量仍然非常非常接近于0。然后在更新步骤，除以第二动量（此时是一个很小的数，就会得到一个很大的步长。这个在开始时很大的步长，并不是因为这一步的梯度太大，只是因为我们人为地将第二动量初始化成了0。

你可能会说当你的第一动量也非常小时，第一动量除以第二动量可以互相抵消，此时不会发生问题。有时他们可以互相抵消，此时不影响步长的结果。有时候会让初始的步长非常大，这就会让开局变得非常糟糕。也许我们使用的初始化的值本来就有些不合理，然后遇到一个非常大的步长时，初始化工作就被彻底搞砸了。然后你到了一个并不合适的区域中，最终很难收敛。

### Adam 的完整形式

为了避免这样的问题出现，我们改进一下Adam 的原始形式。**加入偏置校正项，构造无偏估计**，。在下图中，在更新第一动量和第二动量之后，通过使用当前时间步t来构造它们的无偏估计。在后续更新时，使用无偏估计代替原始的动量，这样就得到了 **Adam的完整形式**。

![image-20220413162717935](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131627005.png)

<u>**Q：式子分母中的 $e^{-7}$是用来干吗的？**</u>

A：这个式子出现在 AdaGrad，RMSProp 以及Adam的公式中。**是为了保证除数不为0**，所以就在分母中加上一个很小很小的正的常数。理论上讲是一个超参数，但是这个数的取值对最后结果不能有太大影响，因此就设成10的-7次方。

### Adam tips

 Adam 确实是一个非常好的优化算法，并且对于不同的问题使用Adam 算法都能得到非常不错的结果。因此 Adam 差不多是我的一个用来解决任何新问题的默认算法。你可以在初始时将$β_1$设置为0.9，$β_2$设置为0.99，学习率设置为1e-3或者5e-4。

Adam 算法在一般情况下真的是首选。

### Adam 与其他优化算法对比

可以看到 Adam 算法紫色的这条线，就像是结合了带动量的 SGD和 RMSProp，有一点但是没有
像 SGD 动量一样绕过太多。Adam 也有类似RMSProp的行为，尝试作出在所有维度上都相同的改进。
也许在这个小的三维例子中，你可以看到Adam 收敛起来和其他算法一致。但是实质上它结合了 SGD 动量和 RMS Prop的特征。

![image-20220413164349565](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131643677.png)

<u>**Q： 还有哪些问题是Adam解决不了的？神经网络会不会仍然很大，仍然花费很长的时间来训练？**</u>

这张图上的损失函数等高线图看起来像个椭圆，想象着我们是是在沿着每个维度独立地去做估计。
这允许我们沿着不同的坐标轴加速或者减速，如果是个墨西哥卷饼状的更高线图，它不是沿着坐标轴对齐的，然而我们还是沿着每个轴独立地去做估计，这就相当于把这个卷饼沿着水平和竖直的方向压缩，但是你无法扭正它。在这种倾斜的等高线图的糟糕情况下，Adam或者上面其他的算法都是没法解决的。

# learning rate tips

当你使用不同的学习率时，有时候太高了就会导致损失函数爆炸，如黄色的曲线。如果学习率很小，如蓝色的曲线，可能要花很长的时间才收敛。挑选正确的学习率确实需要点技巧。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131650093.png" alt="image-20220413165028040" style="zoom:50%;" />



这个技巧是：**把学习率沿着时间衰减**。有点像是结合了左图中不同的曲线的效果，而且是每个图里好的性质。**比如在训练开始的时候用较大的一些学习率，然后在训练的过程中逐渐衰减地越来越小**。
一个衰减的策略是**步长衰减**，比如在第10 万次送代时可以衰减一个因子然后继续训练。
还有**指数衰减**，这种是训练时持续衰减。图中包含了学习率连续衰减的不同做法。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131653413.png" alt="image-20220413165330373" style="zoom: 50%;" />

如果你读论文特别是残差网络那篇论文，你会经常看到下图像这样的曲线。可以看到损失先一直下降，然后骤降再然后平坦，接着又骤降。这些曲线背后其实是他们在用**步长衰减的学习率**。
损失曲线中出现骤降的地方就是在迭代时把学习率乘上了一个因子。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131657693.png" alt="image-20220413165705650" style="zoom:50%;" />

**降低学习率的想法**是说，假设模型已经接近一个比较不错的取值区域，但是此时的梯度已经很小了
，保持原有学习速率只能在最优点附近来回。如果我们降低了学习率，自标函数仍然能够进一步降低，即在损失函数上进一步降低。这个方法在实际中很有用，，不过值得指出的一点是，带动量 SGD 的学习率衰减很常见，但是像 Adam 的优化算法就很少用。

另一点要指出的是学习率衰减是一种二阶的超参数。**你通常不应该一开始就用上学习率衰减这样的事情**。通常你想要让神经网络开始工作，你想要挑选一个不带学习率衰减的不错的学习率来作为开始。如果尝试在交叉验证中同时调整学习率衰减和初始学习率，等等其他的事情你会一头雾水的。
**设置学习率衰减的方法**是先尝试不用衰减看看会发生什么，然后仔细观察损失曲线，看看你希望在哪个地方开始衰减。

# 一阶优化算法

我们之前谈过的所有这些算法，都是一阶优化算法。
下图是自标函数曲线，当前点是这个红色的点。我们在这个点上，求一个梯度。我们用梯度信息来计算，这个函数的线性逼近，这个相当于是对我们的函数进行的一阶泰勒逼近。
现在假设我们的一阶逼近就是实际的函数，然后我们想要迈出一步来找到逼近的最小值，但是这个逼近在稍大的区间内并不成立，所以我们不能朝那个方向一下走太多。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131721110.png" alt="image-20220413172150050" style="zoom: 33%;" />

# 二阶优化算法

其实我们可以使用二阶逼近，同时考虑一阶和二阶偏导信息。现在我们对函数做一个二阶泰勒逼近
，就是用一个二次函数来局部逼近我们的函数。因为是二次函数可以直接跳到最小值点，这就是二阶优化的思想。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131722528.png" alt="image-20220413172257457" style="zoom:50%;" />

# 牛顿法

当把这个思想推广到多维的情况就会得到一个叫做**牛顿步长**的东西。
计算**海森矩阵**，即二阶偏导矩阵，接着求这个海森矩阵的逆，以便直接走到对损失函数用二次逼近后的最小值的地方。跟之前的更新规则比，这里没有学习率。至少在这个牛顿法的原始版本中不需要学习率，每次只需要直接走到最小的点就可以了。然而实际中，你可能也会用上一个学习率，因为这个二次逼近也不是完美的，你可能只是想要沿着二次函数最小值的方向前进，而不是走到最小值的位置。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204131907573.png" alt="image-20220413190726510" style="zoom:33%;" />

对深度学习来说，使用海森矩阵有点不切实际。因为这个海森矩阵是 N* N的，其中 N 表示网络中参数的个数。如果 N 是一亿，那么N*N一亿的平方非常非常大.内存肯定是存不下的，也没办法求这个矩阵的逆。所以经常用拟牛顿法来替代牛顿法，不是直接地去求完整的 Hessian 矩阵的逆，而是去逼近这个矩阵的逆，常见的是低阶逼近。

# 集成算法

目前我们讲过的所有策略都是在减少训练误差和最小化目标函数，但是实际上我们并不在意训练误差。**我们更在意在没见过的数据上的表现**，我们很在意减少训练误差和测试误差之间的差距。现在的问题是如果我们已经很擅长优化目标函数要怎么做来减少训练和测试之间的误差差距以使得我们的模型在没见过的数据上表现的更好呢?
一个快速、笨批又简单的方法是**模型集成**。思想很简单，比起使用一个模型，我们选择从不同的随机初始值上训练10个不同的模型。在测试时我们就会在10个模型上进行测试，然后平均10 个模型的预测结果。把这些多个模型加到一起，能够缓解一点过拟合，从而提高一些性能。通常会提高几个百分点，这不是很巨大的提升，但是却是很固定的提升。在 Image Net 竞赛中或者其他类似的比赛，集成技术是很常见的。这样能够得到最大的性能。

## 集成算法 tips

再发挥一下创造力，有时候可以不用独立地训练不同的模型，你可以在训练的过程中，**保留多个模型的快照，然后用这些模型来做集成学习**。在测试阶段你仍然需要把这多个快照的预测结果做平均、但是你可以在训练的过程中收集这些快照。

![image-20220413210325689](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220413210325689.png)

这里是这周 I CLR 会议上面一篇非常好的论文。这里我们用了一个疯狂的学习率计划，学习率开始时很慢，然后非常快~接着又很慢再然后又特别快。
学习率计划的思想是，这样的学习率会使得训练过程中模型会收敛到目标函数不同的区域。如果你对这些不同的快照做集成以后就能够大幅提高最后的性能，虽然在这个过程中只进行了一次训练。

**<u>Q: 我们已经知道训练和测试错误率相差很大是个不好的现象，这意味着过拟合。但如果它们相差不大就一定好吗?我们真正想要的是不是在两者之间找到一个足够小又最佳的差距呢?</u>**

A：我们其实不在乎这个差别，**我们真正在乎的是在验证集上得到最优的结果**。一般情况下，如果你看不到这个差别，你应该还有很多种方法提升效果。比如通过来达到一点过拟合，在验证集上的测试效果和刚才提到的差距大小。它们之间有一种种怪异的关联性，但我们只关注模型在验证集上的效果。

**<u>Q：集成学习中的超参数是否相同？</u>**

A：有时候它们并不是一样的。可以尝试不同尺寸的模型，不同的学习速率，不同的正则化策略。然后把它们放到一起集成学习。

另外可能会用到的一个小技巧是，在训练模型的时候，对不同时刻的每个模型参数，求指数衰减平均值。从而得到网络训练中一个比较平滑的集成模型。这个方法叫做**Polyak 平均数**。

![image-20220413213118157](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220413213118157.png)