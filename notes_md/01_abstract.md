# 计算机视觉

**计算机视觉**顾名思义就是针对视觉数据的研究。

世界上的摄像头比人更多，每天都产生有超级超级多的视觉数据。2015年的研究数据表示，估计在2017年，互联网大约80%的流量都是视频。从一个纯粹的数据占比的角度来说，在互联网上传播的大多都是视觉数据。那么如何使用算法来开发和利用这些数据呢？视觉数据存在问题，它们真的很难理解，有时我们把视觉数据称为互联网的暗物质，将它与物理学中的暗物质类比。在物理学中，暗物质占整个宇宙质量的一大部分，我们能知道是因为在各种天体上存在万有引力，我们不能直接观察到它。互联网上的视觉数据也是一样的，它们占网络传输数据的大部分，但是算法很难去探知并理解这些视觉数据到底是些什么。

另一个统计实例来自 YouTube，大概每秒钟世界上发生的事情其中有长达五小时的内容会被上传到 YouTube。如果想要给视频分类，为观众推荐相关视频，通过投放广告来赚钱 ，我们希望使用技术，让机器可以沉浸式观测并且理解这些视觉数据。
所以这个计算机视觉领域是一个跨学科的领域。

# 计算机视觉发展历程

## 背景

### 生物视觉的历史

视觉的历史可以追溯到很久很久以前。大约5亿4千三百万年前，地球几乎完全被水覆盖，那时候只有少量的物种在海洋中游荡，没什么生机。动物不怎么活跃，没有眼睛。有猎物路过时，它们就抓来充饥。但是在大约5亿4千万年前发生了一件意义重大的事。通过对化石的研究，动物学家发现在短短的一千万年里，动物的物种数量爆炸式增长，从少数几种发展到成百上千，被称为物种大爆炸。是什么造成了这个奇怪的现象呢？有很多相关理论，但这件事仍然是未解之谜。后来，一位名叫 安德鲁 帕克的澳大利亚动物学家提出了一种很有说服力的理论。他发现，距今5亿4千万年前，第一次有动物进化出了眼睛，是**视力功能的出现促使了物种数量的爆炸。**动物们一旦有了视力，生物开始变得更积极主动，捕食者追赶猎物，而猎物要逃避捕食者。视力的出现开启了一场进化的竞赛，物种们为了生存必须尽快地演化。这就是动物拥有视觉的开端。今天，视觉成为了动物，尤其是有智慧的动物最重要的感知系统 。人类的大脑皮层中几乎一半的神经元与视觉有关。这项最重要的感知系统，使我们可以生存，工作，运动，操作器物，沟通，娱乐，等等。以上讲的是生物的视觉。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220503232513053.png" alt="image-20220503232513053" style="zoom: 67%;" />

### 机器视觉的历史

那么人类让机器获得视觉或者说照相机的历史是什么样的？我们现在已知最早的相机，要追溯到17 世纪文艺复兴时期的暗箱。是一种通过小孔成像的相机，与动物早期的眼睛非常相似。通过小孔接收光线，后面的平板收集信息并投影成像。如今照相机已经非常普及了。摄像头可以说是手机或者其它装置上最常用的传感器之一。

![image-20220503235108223](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220503235108223.png)

同时，生物学家也开始研究视觉的机理。其中最具影响力的要数五六十年代休伯尔和维泽尔使用电生理学的研究。这个研究启发了计算机视觉的研究。
他们提出的问题是哺乳动物的视觉处理机制是怎样的。他们选择与人类相似的猫类来进行研究，他们将电极插进主要控制猫视觉的后脑上的初级视觉皮层，然后观察何种刺激会引起视觉皮层神经的激烈反应。
他们发现猫大脑的初级视觉皮层有各种各样的细胞，简单的细胞会在有向边沿着特定方向移动时有反应。复杂细胞对光线方向和移动有反应。总的来说，**视觉处理是始于视觉世界的简单结构**。视觉信息变化，大脑建立了复杂的路径，直到它可以识别更为复杂的视觉世界。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220503233423079.png" alt="image-20220503233423079" style="zoom:67%;" />

### 计算机视觉历史

计算机视觉的历史也从60 年代初开始的，Block World 是由 Larry Roberts 出版的一部作品，被公认为是计算机视觉的第一篇博士论文。其中视觉世界被简化为简单的几何形状，目的是容易识别，并重建这些形状。

![image-20220504000308604](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504000308604.png)

1966年，有一个MIT暑期项目叫做The Summer Vision Project。它如今已经非常著名。这个项目的目标是有高效利用暑期时间来构建视觉系统的重要组成部分。五十年过去了，计算机视觉领域已经那个夏季项目发展成为全球数千名研究人员的领域。我们还没有弄清楚人类视力的原理，但是我们已经能够处理一些简单的问题。这个领域已经成为人工智能领域最重要和发展最快的领域之一。

另一件不得不提是是一个叫做David Marr的人，他是麻省理工学院视觉科学家。在70年代后期，他撰写了一本非常有影响力的书——《VISION》。内容是关于他对视觉的理解，以及如何处理计算机视觉开发 和让计算机识别视觉世界的算法。他在书中指出，为了拍摄一幅图像并最终全面的3D视觉表现，必须经历几个过程。**第一个过程叫做 原始草图**，这个阶段由边缘，端点，虚拟线条，曲线，边界等组成。这是受到了神经学家的的启发，Hubel 和 Wiesel 告诉我们，视觉处理的早期阶段有很多关于像边缘的简单结构。**下一过程是2.5 维草图**，将表面，深度信息，层等拼凑在一起，然后最终将所有内容放在一起成为一个3d 模型。

![image-20220504001111140](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504001111140.png)

这是一个进入视觉领域非常直观的方式——考虑如何解构视觉信息。
七十年代，有一个开创性的工作组提出来一个问题，我们如何越过简单的块状世界识别或表示现实世界的对象？斯坦福大学的两个科学家组提出了类似的想法，一个被称为广义圆柱体 ，一个被称为图形结构。基本思想是每个对象都由简单的几何图单位组成。
例如，一个人可以通过广义的圆柱形形状拼接在一起。或者也可以由一些关键元素按照不同的间距组合在一起。所以表示方法是将物体的复杂结构简约成一个几何体，有更简单的形状和几何结构。

![image-20220504002636434](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504002636434.png)

80年代 ，David Lowe 思考如何重建或者识别由简单的物体结构组成的视觉空间。他尝试识别通过线和边缘构建的剃须刀。其中大部分都是直线以及直线之间的组合。
从60年代到80年代，我们都试图去解决目标识别问题。在这个过程中，人们开始思考，如果目标识别太难了，那可以先做**目标分割，就是把一张图片中的像素点归类到有意义的区域，**我们可能不知道这些像素点组合到一起是一个人型，但是我们可以把属于人的像素点从背景中抠出来，这个过程叫做图像分割。

![image-20220504003033708](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504003033708.png)

还有另一个问题先于其他的计算机视觉问题有进展，那就是**面部检测**。大概在 1999-2000年，机器学习技术 ，特别是统计机器学习方法开始加速发展。出现了一些方法，比如支持向量机模型，boosting 方法，图模型，包括最初的神经网络。Paul Viola 和 Michael Jones 使用AdaBoost 算法进行实时面部检测。这项工作是在计算机芯片还是非常慢的2001年完成的，但是他们还是能够实现准实时的面部检测。在论文发表的第5年，也就是2006年，富士推出了第一个实现实时面部检测的数码相机。这是从基础科学研究到实际应用的一个快速的转化。

![image-20220504003433742](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504003433742.png)

怎样才能够做到更好的目标识别呢？在90年代末到2000年，目标识别的思想是基于特征来做。这是由David Lowe 发明的，叫做SIFI特征。例如这里有一个stop标识，去匹配另一个stop标识是非常困难的。因为有很多变化的因素，如相机的角度，遮挡视角，光线，及目标自身的内在变化。但是可以得到一些启发，标的某些特征可以在变化中具有表现性和不变性。**可以观察这些不变的特征来进行识别**。所以目标识别的首要任务是在目标上确认这些关键的特征，然在在目标物体上匹配这些特征，这比匹配整个目标要容易得多。
下图是一张他论文中的图，图中显示了一个stop 标志几个SIFT特征，这些特征与另一个stop 标识的 SIFT 特征相匹配。

![image-20220504003923986](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504003923986.png)

使用相同的图片特征，怎么识别整幅图的场景呢？这里有一个例子叫做空间金字塔匹配。背后的思想是图片有各种特征，这些特征可以告诉我们图片是什么类型的，是风景，厨房，还是公路等等。这个算法从图片各部分和不同像素中抽取特征，并把他们放在一起作为特征描述符然后在特征描述符上做支持向量机。

![image-20220504004759016](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504004759016.png)

还有一项类似的研究。把这些特征放在一起以后，研究如何在实际图片中比较合理地合成人体姿态，辨认人体姿态。这方面一个工作被称为方向梯度直方图，
另一个被称为 可变性不见模型。

![image-20220504004903196](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220504004903196.png)

