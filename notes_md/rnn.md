# 回顾

跟随 Image Net分类挑战比赛中获胜者的脚步，上节课我们讲的是 CNN 架构。

首先是 2012年的 **AlexNet架构**，**它是一个9层的卷积网络，它在计算机视觉领域开展了一场深度学习的革命。**

然后是2014年的**VGG**和**GoogleNet**，它们的构架变得更深。**VGG是拥有16层和19层的模型，Google Net是一个22层的模型。**由于在2014年，批量归一化还没有出现，训练约20 层的深层模型是非常具有挑战性的。所以，这两种模型都需要借助一些技巧才能使它们收敛。对于 VGG，它有16层和19层的模型，首先训练了一个11 层的模型，让这个较为浅的模型先收敛，然后在中间添加一些额外的随机层继续训练，便得到了16层和19层的模型。对于GoogleNet，使用了一些辅助分类器，这不是为了让获得更好的分类性能，是一种可以将额外的梯度直接注入到网络尾部中的方法。有了批量标准化，这些技巧都不再需要了。

接着是2015年的**ResNet**，称为**残差网络，它通过一些小的残差块连接。我们将输入传递到残差块，然后加上卷积层的输出。这是一种有趣的构架**，它有两个属性，一是如果我们把残差块中所有的权值设为零，那么所有的残差块就是恒等的。在某种程度上，这个模型相对容易训练。而且这解释了在神经网络中使用L2正则化的原因。L2正则化会迫使参数趋近于0。在残差网络中参数逐渐趋向于0，那就是促使模型不再使用它不需要的层，驱使残差块走向恒等。另一个属性是残差网络与反向路径中的梯度流有关，如果你还记得在反向传播中加法门的工作原理，当上游梯度通过加法门时，将沿着两个不同的路径，一是通过卷积块，二是通过残差连接直接连接到梯度。当成百上千个残差块堆叠在一起时，残差连接给梯度提供了一条“高速公路”，使梯度在整个网络中反向传播，这让网络的训练变得更快更容易。

在机器学习领域中，管理模型梯度流是非常重要的思想。在递归神经网络中也是很普遍的。

然后是**DenseNet**,**FractalNet** 。**这类模型中都加入了一些额外的恒等连接或梯度的快捷方式**。这些额外的拓扑结构让梯度从网络末端损失层流向整个网络中的不同层，提供了一个直接的路径。在 CNN 构架中合理地管理梯度流，是我们在过去几年里看到的最多的东西。

然后我们看到不同模型中浮点运算量，参数数量和运行时间的比较。可以发现，**像 VGG和 AlexNet 这样的大型模型，拥有大量的参数，大部分来自模型中的全连接层。**如AlexNet大概有6200万个参数，它最后面的全连接层，激活尺寸从6×6×256变成4096的全连接向量。这个权值矩阵的元素个数是6x6x256x4096，约3800万个参数。因此在AlexNet 模型中，一半以上的参数，只存在于最后的全连接层中。对比其他架构，如 GoogleNet 和ResNet ，这些神经网络没有使用这些大型的全连接层，**而是在神经网络的末端使用全局平均池化。**这使得神经网络有更好的架构。大幅降低参数的数量。这就是关于 CNN 架构的简要回顾。

# 任务分类

机器学习中会有各种任务的分类，根据输入和输出是否可变，可以分为以下类别。

## 一对一

这是我们之前最常看到的基础网络结构，**输入接受固定尺寸的对象**，比如一幅图片或者一个向量，通过隐层给出**单一的输出结果**，比如一个值，一个分类或者一组类别，叫做**香草（vanilla）前馈网络**。它的结构是一对一的。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261248455.png" alt="image-20220426124802065" style="zoom:50%;" />

## 一对多

一对多的网络结构，**输入是固定尺寸的对象**，**输出是长度可变的序列**。比如图片描述就是这样一个任务。不同的描述可能造成单词量的不同，因此输出值的长度需要是一个变量。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261249913.png" alt="image-20220426124938883" style="zoom:50%;" />

## 多对一

输入的尺寸是可变的，输出是固定的。比如输入一段文字，判断文字的情感属性是消极情感还是积极情感。或者在输入一个视频，整个视频的时间是不固定的，做出分类决策，判断视频中做了什么活动。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261254270.png" alt="image-20220426125411229" style="zoom:50%;" />

## 多对多

输入和输出都是可变的，比如机器翻译，输入英文句子，输出法文句子，英语句子的长度可能与法语句子不同，因此需要模型能够同时容纳输入和输出的长度可变序列。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261256406.png" alt="image-20220426125606357" style="zoom:50%;" />

另外还有一种，也是多对多，但是输入和输出的长度是相同的。例如一段有序的视频，帧数是一个变量，我们要对该序列中的每个元素做出决策，在输入是视频的情况下，对每一帧都做分类决策。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261423504.png" alt="image-20220426142336472" style="zoom:50%;" />

# RNN

RNN是**Recurrent Neural Networks，递归神经网络**的简称。

它是用于**处理长度可变的有序数据的一类模型**，让我们可以比较自然地理解模型的不同的架构。**即使对有固定输入大小**
**和固定输出大小的问题，RNN 也同样很有用。**

举个例子，我们收到了一个固定大小的输入，如一幅图像，要做出分类决策，判断图像中的数字是多少。不是做单一的前向传播，马上做出决策，而是观察图片的各种不同部分之后，做出最终决策，判断数字到底是几。

在这一例子中，输入是图片，输出是分类决策。在这样的情况下
利用 RNN 网络来处理长度可变的序列数据，也会形成一些有意思的模型。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271213135.png" alt="image-20220427121001478" style="zoom:50%;" />



有一份论文[ A Recurrent Neural Network For Image Generation”](http://proceedings.mlr.press/v37/gregor15.html)运用了这一想法来生成新的图像。任务是模型来合成
新的图片，这些图片看上去像之前训练的那些图片相似。
可以用 RNN 架构来绘制出这些输出图像，大约一次绘制一幅图像。虽然输出是固定尺寸的图像，我们可以让这些模型一直工作
每次计算出一部分输出，这样就可以用 RNN来完成了。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271219098.png" alt="image-20220427121950821" style="zoom:50%;" />

## 原始循环神经网络

那么RNN到底做的是什么呢？

每个 RNN 网络都有这样一个小小的**循环核心单元**，它把 x 作为输入，RNN 有一个**内部隐藏态(internal hidden state )**，这一隐藏态会在 RNN 每次读取新的输入时更新。当模型下一次读取输入时，内部隐藏态会反馈至模型 。因此，就有了这样的模式 ，**读取输入，更新隐藏态，并且生成输出。**

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271300899.png" alt="image-20220427130059858" style="zoom:33%;" />

用公式来表达的话，就是 
$$
h_{t} = f_W(h_{t-1},x_t)
$$
其中，$h_{t}$ 表示更新的隐藏态，$h_{t-1}$ 表示上一次的隐

藏态，$x_t$ 表示当前输入，$f_W$ 表示依赖权重 $W$ 的函数。

在RNN的模块中，我们使用函数 f 对循环关系进行计算。函数接收隐藏态$h_{t-1}$ 和 $x_t$ ，输出更新后的隐藏态 $h_t$。读取下一个输入时，$h_t$ 和 $x_{t+1}$ 参数再次传入函数 $f_W$ 。 如果想要在网络的每一步都生成输出，可以增加全连接层，每一步都将$h_t$ 作为输入，根据每一步的隐藏态做出决策。要注意的一点就是，用的是同样的函数$f_W$，同样的权重$W$。

使用 $tanh$ 作为  f 函数，可以写成下式。用权值矩阵 $W_{hh}$和输入 $x_t$ 相乘，另一个权值矩阵 $W_{hh}$ 和 $h_{t-1}$ 相乘，再将两个相乘的结果详见，最后用tanh 函数将结果缩放到-1~1 中。这样，系统中就引入了一些非线性元素。
$$
h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t) \\
y_t = W_{hy}h_t
$$

## 计算图

### 多对多计算图

当我想到-RNN 时，从两方面来思考它。第一，它有一种隐藏态
可以循环反馈给自我。这张图有让人疑惑，将这张计算图展开更多的时步，隐藏态里的数据传输流，以及输入，输出，权重的走向就变得更为清晰了。

在第一时步，有初始隐层状态$h_0$，通常情况下$h_0=0$,有输入项 $x_t$，会被代入$f_W$ 函数中，计算得出下一个隐层状态$h_1$。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271434429.png" alt="image-20220427143433393" style="zoom:33%;" />

得到下一个输入项后，重复这个过程。将$h_1$和 $x_2$代入之前的方程$f_W$，得到新的输出项 $h_2$。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271437144.png" alt="image-20220427143756107" style="zoom: 33%;" />

这个过程将会不断重复，直到用完输入序列的输入项$x_t$。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271439242.png" alt="image-20220427143908187" style="zoom: 33%;" />

现在我们可以让这个过程更为清楚一些，将权重矩阵写在我们的计算流程图上。能看到在每个步长中，**使用相同的权重矩阵W**。这个$f_W$ 块，虽然每次接收不同隐藏态和不同的x，但使用相同的$W$ 权重。回想一下反向传播中的梯度流过程，在一张计算图中多次重复使用的相同节点，就在回溯过程中，不断地计算 $d loss/dw$，并最终把所有梯度值加到w 矩阵上。
如果将反向传播的原理应用到这个模型中，你会得到在每一个时步下计算出的梯度。最终的w 梯度是所有时步下独立计算出的梯度之和。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271447278.png" alt="image-20220427144748230" style="zoom:33%;" />

同样可以直接把 $y_t$写在这张计算图上，这样每个计算步长下输出的$h_t$，作为输入给之后的神经网络，输出该时步下的$y_t$。
$y_t$ 可以是每个时步的类别得分或是其他类似的东西。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271447190.png" alt="image-20220427144702128" style="zoom: 33%;" />

然后来看损失。在大多数情形下，每一个时步都有一个与输入序列对应的真实标签。这样就可以计算出每个时步下输出相对应的损失值，通常是`softmax` 损失之类。计算这样的损失，需要序列在每个时步下都有与之对应的真实标签。最终的损失值是这整个训练中这些单独的损失值的总和。得到每个时步的损失值，把它们加起来，就得到了最终的损失值。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271451110.png" alt="image-20220427145107030" style="zoom:33%;" />

为了训练这个模型，我们需要计算损失函数在 W 上的梯度。最终的损失值又会回溯到每一个时步的损失，然后每一个时步又会各自计算出在权重 $w$ 上的梯度。它们的总和就是权重$w$的最终梯度。

### 一对多计算图

多对一的情形可以表示成下图。比如做诸如情感分析之类的工作，通常根据网络最终的隐层状态做出决策，因为最终隐层状态
整合了序列中包含的所有情况。

一对多问题，接收固定长的输入项，输出不定长的输出项。之后这个固定长的输入项会被初始化为模型的初始隐层状态，递归神经网络会对输出的单元逐个进行处理，最终得到不定长的输出序列。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271454996.png" alt="image-20220427145452939" style="zoom:33%;" />

### 多对多计算图

sequence to sequence 模型，比如机器翻译之类的问题。输入一个不定长的序列，输出一个不定长的序列。**把它看作是多对一情形与一对多情形的组合**。这样就存在两个过程，分别是编码器与解码器。

以机器翻译为例，在编码器阶段，接收一个不定长度的输入序列，可能是一个英语句子，然后整个句子会被编码器网络所编码成一个单独的向量。这是多对一的情形。

第二部分的解码器网络，是一对多的情形，它的输入就是前面编码完成的向量。生成的是一个不定长输出序列，是用另一种语言翻译过来的句子。

对于不定长输入，在每一个时步下做出预测，比如预测接下来的用词。想象一下把整个训练过程的计算图展开，然后对输出序列的损失求和，像之前一样应用反向传播来训练这个模型。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271500671.png" alt="image-20220427150048609" style="zoom:50%;" />

## 字符级的语言模型

递归神经网络经常用于语言建模。**语言建模就是，想要读取一些语句，就要让神经网络在一定程度上学会生成自然语言。**这在字符水平上是可行的，让模型逐个生成字符。同样，在单词层面上也可行，让模型逐个生成单词。

### 输入表示

举一个简单的例子，有一个字符级的语言模型，网络读取一串字符序列，然后它需要去预测文本流的下一个字符是什么。字符表由4个字母组成，分别是 h，e，l，o。有一个训练样本序列是hello。

**使用 one-hot 向量表示字符序列，将其作为$x_t$输入到我们的递归神经网络中。**单词中，每个字母将会由一个向量表示，其他位置都为0，只有对应单词中字母所在位置的那个元素是1 的单位向量来表示。

在这个例子中，因为单词是由四个字母h，e，l，o组成。用四维向量表示输入序列中的字母。因此，h,e，l，o 用向量可以表示为

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204281348041.png" alt="image-20220428134802454" style="zoom: 50%;" />

### 训练阶段

在第一个时步中，网络接收输入h，该输入项会进入到第一个RNN 单元内，之后输出$y_t$，即为网络对组成单词的每个字母做出的预测，也就是它认为接下来最可能出现的的字母。在这个例子，训练的字母序列是hello，那么下一个正确的字母应该输出e，但模型在做的只是预测认为 o 最有可能是下一个字母。这里预测结果就是错误的。可以使用 Softmax 损失函数来度量我们对这些预测结果的不满意程度。下个时步中，输入第二个字母e，重复执行这个过程。将e 表达为一个向量，利用这个新的输入向量以及之前计算出的隐层状态，生成输出一个新的隐层状态。再次做出预测，我们希望模型做出的预测将是 l，模型预测输出的是o，这时候高损失就出现了。不断重复上述过程，用不同的字母序列去训练这个模型，最终它将会学习到基于之前出现过的字符来预测接下来应出现的字符。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204281359686.png" alt="image-20220428135939617" style="zoom:50%;" />

### 测试阶段

训练完成后，模型在测试阶段会发生什么？

我们可能想用该模型测试一下样本，并使用这个训练好的神经网络模型去生成新的文本——类似于
训练所使用的文本。采用的方法是通过输入一些文本的前缀来测试这个模型。

比如前缀只是一个字母h，在递归神经网络的第一步输入字母h，它会产生一个基于词库中所有的字母得分的分布，使用一个softmax 函数将得分转换成一个概率分布，然后从这些概率分布中通过采用得到样本输出，去生成序列中的第二个字母。在这种情况下即使得分情况非常不好，也有可能从这个概率分布图中幸运地得到字母e 。

现在我们把顶端的字母 e 以one-hot 编码的向量形式重新输入到网络中，重复这个过程，生成并输出第二个字母。然后可以一次又一次地重复上述过程去生成一个序列。**该模型生成序列的过程是基于上一个时间步内预测得到的概率分布，在下一个时间步内生成一个新的字母。**

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204281408228.png" alt="image-20220428140829162" style="zoom:50%;" />

**<u>Q：为什么不是输出一个得分最高的字母？</u>**
A：因为我们基于的是字母的概率分布图，在这种情况下不可能得到正确的字母。通过**采样**来解决这个问题。在实际中训练中，有时两者都会看到。可以选取概率最大的字母，这种方法有时会更稳定一些。但是一般来说softmax方法的一个优势在于它可以让你的模型输出结果多样化。模型可能有相同的输入，比如相同的前缀，或者在图像标注时使用相同的图像，如果使用概率分布代替得分最大的，训练模型可以产生多组不同类型的合理的输出序列。这取决于第一个时间步中的样本，这实际上是一个优点，因为输出结果更加多样了。

**<u>Q：在测试阶段是否可以输入整个softmax 向量，而不是一个one-hot向量？</u>**
A：一般不这样做，因为如果在训练时使用softmax向量代替通常会导致两个问题。**第一个问题是测试阶段与训练阶段所使用的数据不同。**一般来说如果让训练好后的模型在测试阶段去做一些与训练阶段不同的任务，那么**模型会产生一些偏差**，它通常会输出一些让人沮丧无用的信息。**另一个问题是计算效率问题**。刚刚讲的简单实例中，词库里只有四个元素，问题规模不大。但在实际操作中，词库可能非常大。如果想一次输出若干个单词，词库就是英语中所有的单词。在实际训练中one-hot 向量，通常是用稀疏向量而不是用密集向量。如果想加载10,000个元素的softmax向量，在计算时间上可能会比较长。就是为什么我们通常在测试阶段也使用one -hot 向量。

### 沿时间的反向传播 

**假设有一个序列，每个时间步产生一个输出结果，最后计算一些损失值，这就是沿时间的反向传播方法。**在前向传播过程中，沿着时间做前向计算，然后在反向传播过程中，是逆着时间反向计算所有的梯度。这个过程实际上有些麻烦。如果想要训练一个很长的序列，比如我们要训练一个基于维基百科里所有文本的神经网络语言模型，计算过程非常耗时。每次我们计算梯度时，必须做一次前向计算，遍历维基百科的所有文本，然后反向传播每次也会遍历所有文本，并重新计算一次梯度。这个过程非常缓慢，所以模型很难收敛，并且占用非常大的内存。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204281458836.png" alt="image-20220428145812802" style="zoom: 67%;" />

### 截断沿时间反向传播

在实际应用中们通常采用一种近似方法，称为沿时间的截断反向传播方法。这个方法的思想是即使输入序列很长很长，甚至趋近于无限。在训练模型时，**前向计算若干步，比如100 。**也就是说前向计算100步，仅仅计算子序列的损失值，然后沿着这个子序列反向传播并计算梯度更新参数。重复上述过程，仍然可以得到网络中的一些隐藏状态。这是从第一批数据中计算得到的，当计算下一批数据时使用这些隐藏状态，所以前向计算过程是相同的。

基于下一批数据计算梯度时，只能根据第二批数据反向传播。现在我们基于沿时间的截断反向传播法计算一次梯度，这个过程会持续到使用下一批数据的时候。复制这些隐藏层的状态值，但是前向计算和反向传播都只是持续一定数量的时间步。

当我们在讨论基于大规模数据集训练模型时，使用数据集中所有样本来计算梯度开销非常大，可以抽取一小部分样本然后用小样本集的数据来计算。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204281529462.png" alt="image-20220428152946408" style="zoom:67%;" />

[这里](https://gist.github.com/karpathy/d4dee566867f8291f086)是实现字符级的RNN模型的一个例子。仅仅使用了112 行 Python 代码，能处理并构建词汇。它使用截断沿时间反向传播算法来训练网络模型，
然后计算样本的输出。

## RNN的应用的几个例子

### 一个莎翁风格文章的RNN模型

比如基于文本来训练RNN语言模型，然后生成新的类似风格的文本。在这个实例中，摘取了莎士比亚文集中的文本当作训练数据集，来训练模型。

可以看出在训练的初始阶段，产生的是毫无意义的内容。随着整个训练过程的进行，最终产生相对能理解的内容。在模型已经被训练得非常好之后，它会生成一些看起来非常有莎翁风格的文章。如果再继续训练下去进一步收敛，然后对一些长句子采样，它看上去真的像一部莎翁的戏剧。这仅仅是从莎士比亚文本的结构中学到的东西。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220429235403743.png" alt="image-20220429235403743" style="zoom:67%;" />

![image-20220429235642844](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/image-20220429235642844.png)

