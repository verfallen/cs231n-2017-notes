# 回顾

跟随 Image Net分类挑战比赛中获胜者的脚步，上节课我们讲的是 CNN 架构。

首先是 2012年的 **AlexNet架构**，**它是一个9层的卷积网络，它在计算机视觉领域开展了一场深度学习的革命。**

然后是2014年的**VGG**和**GoogleNet**，它们的构架变得更深。**VGG是拥有16层和19层的模型，Google Net是一个22层的模型。**由于在2014年，批量归一化还没有出现，训练约20 层的深层模型是非常具有挑战性的。所以，这两种模型都需要借助一些技巧才能使它们收敛。对于 VGG，它有16层和19层的模型，首先训练了一个11 层的模型，让这个较为浅的模型先收敛，然后在中间添加一些额外的随机层继续训练，便得到了16层和19层的模型。对于GoogleNet，使用了一些辅助分类器，这不是为了让获得更好的分类性能，是一种可以将额外的梯度直接注入到网络尾部中的方法。有了批量标准化，这些技巧都不再需要了。

接着是2015年的**ResNet**，称为**残差网络，它通过一些小的残差块连接。我们将输入传递到残差块，然后加上卷积层的输出。这是一种有趣的构架**，它有两个属性，一是如果我们把残差块中所有的权值设为零，那么所有的残差块就是恒等的。在某种程度上，这个模型相对容易训练。而且这解释了在神经网络中使用L2正则化的原因。L2正则化会迫使参数趋近于0。在残差网络中参数逐渐趋向于0，那就是促使模型不再使用它不需要的层，驱使残差块走向恒等。另一个属性是残差网络与反向路径中的梯度流有关，如果你还记得在反向传播中加法门的工作原理，当上游梯度通过加法门时，将沿着两个不同的路径，一是通过卷积块，二是通过残差连接直接连接到梯度。当成百上千个残差块堆叠在一起时，残差连接给梯度提供了一条“高速公路”，使梯度在整个网络中反向传播，这让网络的训练变得更快更容易。

在机器学习领域中，管理模型梯度流是非常重要的思想。在递归神经网络中也是很普遍的。

然后是**DenseNet**,**FractalNet** 。**这类模型中都加入了一些额外的恒等连接或梯度的快捷方式**。这些额外的拓扑结构让梯度从网络末端损失层流向整个网络中的不同层，提供了一个直接的路径。在 CNN 构架中合理地管理梯度流，是我们在过去几年里看到的最多的东西。

然后我们看到不同模型中浮点运算量，参数数量和运行时间的比较。可以发现，**像 VGG和 AlexNet 这样的大型模型，拥有大量的参数，大部分来自模型中的全连接层。**如AlexNet大概有6200万个参数，它最后面的全连接层，激活尺寸从6×6×256变成4096的全连接向量。这个权值矩阵的元素个数是6x6x256x4096，约3800万个参数。因此在AlexNet 模型中，一半以上的参数，只存在于最后的全连接层中。对比其他架构，如 GoogleNet 和ResNet ，这些神经网络没有使用这些大型的全连接层，**而是在神经网络的末端使用全局平均池化。**这使得神经网络有更好的架构。大幅降低参数的数量。这就是关于 CNN 架构的简要回顾。

# 任务分类

机器学习中会有各种任务的分类，根据输入和输出是否可变，可以分为以下类别。

## 一对一

这是我们之前最常看到的基础网络结构，**输入接受固定尺寸的对象**，比如一幅图片或者一个向量，通过隐层给出**单一的输出结果**，比如一个值，一个分类或者一组类别，叫做**香草（vanilla）前馈网络**。它的结构是一对一的。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261248455.png" alt="image-20220426124802065" style="zoom:50%;" />

## 一对多

一对多的网络结构，**输入是固定尺寸的对象**，**输出是长度可变的序列**。比如图片描述就是这样一个任务。不同的描述可能造成单词量的不同，因此输出值的长度需要是一个变量。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261249913.png" alt="image-20220426124938883" style="zoom:50%;" />

## 多对一

输入的尺寸是可变的，输出是固定的。比如输入一段文字，判断文字的情感属性是消极情感还是积极情感。或者在输入一个视频，整个视频的时间是不固定的，做出分类决策，判断视频中做了什么活动。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261254270.png" alt="image-20220426125411229" style="zoom:50%;" />

## 多对多

输入和输出都是可变的，比如机器翻译，输入英文句子，输出法文句子，英语句子的长度可能与法语句子不同，因此需要模型能够同时容纳输入和输出的长度可变序列。

![image-20220426125606357](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261256406.png)

另外还有一种，也是多对多，但是输入和输出的长度是相同的。例如一段有序的视频，帧数是一个变量，我们要对该序列中的每个元素做出决策，在输入是视频的情况下，对每一帧都做分类决策。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204261423504.png" alt="image-20220426142336472" style="zoom:50%;" />

# RNN

RNN是**Recurrent Neural Networks，递归神经网络**的简称。

它是用于**处理长度可变的有序数据的一类模型**，让我们可以比较自然地理解模型的不同的架构。**即使对有固定输入大小**
**和固定输出大小的问题，RNN 也同样很有用。**

举个例子，我们收到了一个固定大小的输入，如一幅图像，要做出分类决策，判断图像中的数字是多少。不是做单一的前向传播，马上做出决策，而是观察图片的各种不同部分之后，做出最终决策，判断数字到底是几。

在这一例子中，输入是图片，输出是分类决策。在这样的情况下
利用 RNN 网络来处理长度可变的序列数据，也会形成一些有意思的模型。

<img src="https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271213135.png" alt="image-20220427121001478" style="zoom:50%;" />



有一份论文[ A Recurrent Neural Network For Image Generation”](http://proceedings.mlr.press/v37/gregor15.html)运用了这一想法来生成新的图像。任务是模型来合成
新的图片，这些图片看上去像之前训练的那些图片相似。
可以用 RNN 架构来绘制出这些输出图像，大约一次绘制一幅图像。虽然输出是固定尺寸的图像，我们可以让这些模型一直工作
每次计算出一部分输出，这样就可以用 RNN来完成了。

![image-20220427121950821](https://raw.githubusercontent.com/verfallen/cs231n-2017-notes/main/img/202204271219098.png)